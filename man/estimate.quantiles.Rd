% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper_get_quantiles.R
\name{estimate.quantiles}
\alias{estimate.quantiles}
\title{Estimate quantiles of a climate time series}
\usage{
estimate.quantiles(defaults, log = T, max.runtime = 4 * 60 * 60,
  assumed.avg.processing.time = 160)
}
\arguments{
\item{defaults}{the output from \code{\link{set.defaults}}, used to set input
parameters (see Section "On \code{get.quantiles} parameters," below)}

\item{log}{whether to log the output using \code{sink()} in the directory
\code{[defaults$aux.data.dir]/run_logs/}. By default, true. Log filenames
are (using run start time):
\code{estimate_quantiles_run_YYYY-MM-DD_HH-MM-SS.txt}.}

\item{max.runtime}{if batch processing on a server with a maximum allocated
runtime, you can set it here, and the run will stop when the next block of
time might take longer to run than the remaining allocated time. This
prevents empty, un-processed temporary output files from preventing the
complete processing of all data 'blocks'. Explicitly, the next block isn't
processed and the function run is interrupted if the current system time if
\code{start.time + max.runtime - Sys.time() < (2 * 160)*[num pixels in
block] seconds}, assuming that it takes roughly 160 seconds per pixel to
run this code (for 40 runs, 121 years of data, on the server this code was
written on etc.); this time assumption can be changed with the
\code{assumed.avg.processing.time} option, detailed below.}

\item{assumed.avg.processing.time}{by default 160 (seconds), the estimated
processing time per pixel. Used in interrupting batch run if time is
running out.}
}
\value{
Nothing. Output is saved instead.
}
\description{
This is a wrapper for \code{\link{get.quantiles}} that allows for file
management, batch processing, bootstrapping, and saving of output, if all the
directory and filename/structure defaults are followed, for the estimation of
quantiles across model time series, with potentially multiple runs of data
over the same time frame.
}
\details{
\code{estimate.quantiles} runs \code{\link{get.quantiles}} on a
pixel-by-pixel basis. These pixels are loaded and processed on a
latitude-by-region/subset basis - in other words, a 'block' of pixels is
every pixel in one subset/region (determined by a separate .nc file in the
\code{mod.data.dir} set by the \code{\link{set.defaults}} function) with the
same latitude. This 'block' of pixels is loaded and sent through
\code{\link{get.quantiles}} one at a time; the resultant coefficients are
saved in files 'block' by 'block'. The 'blocks' are identified through the
saved output of \code{\link{get.process.chunks}}.
}
\section{Loading basis functions}{

 This function assumes that needed basis functions have already
 been created using \code{\link{get.predictors}} and attempts
 to load them (this is the most computationally efficient way
 of dealing with them). It otherwise regenerates them.
}

\section{On \code{\link{get.quantiles}} parameters}{

 Inputs to \code{\link{get.quantiles}} are governed through the
 \code{defaults} object, generated by the \code{\link{set.defaults}}
 function. These include which quantiles to estimate (\code{q_norm},
 \code{q_bulk}, \code{q_tail}), how many degrees of freedom to use in the
 predictor variables (\code{df.x}, \code{df.t}, \code{df.xt}), what years to
 process (\code{year.range}), and whether to add the volcanic forcing data
 (\code{get.volc}). See \code{\link{get.quantiles}} and
 \code{\link{set.defaults}} for details. Additionally, bootstrap/uncertainty
 quantification parameters(\code{bootstrapping}, \code{nboots}, and
 \code{block.size}) are set; these are used in this wrapper to govern
 bootstrapping.
}

\section{On processing efficiency}{

\code{estimate.quantiles} does not explicitly support parallel processing
\strong{within} the function (various \code{mclapply} instances were tried
without promising results). \strong{However}, the creation of temporary
output files at the start of processing and built-in testing for the
existance of the output files means that this function can be called from
multiple instances of R (for example in running in batch) without overwriting
work done by other instances.

This is the most computationally-intensive step in the
package.
}

